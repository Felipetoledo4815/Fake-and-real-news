{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.5.6 64-bit ('cnn': conda)",
      "language": "python",
      "name": "python35664bitcnnconda56357701081d4b1c93b6934220d67c02"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "BERT_news_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2fq8wgxNfVu"
      },
      "source": [
        "# !pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgjep_51NTaF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# torchtext libraries\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator, Dataset\n",
        "\n",
        "# huggingface libraries\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpY8IUtYNTaK"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2ogmpxNTaL"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voijfr7pNTaL"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ykqOx6TNTaL"
      },
      "source": [
        "MAX_SEQ_LEN = 128\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long)\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "fields = [('text', text_field), ('label', label_field)]\n",
        "train, valid, test = TabularDataset.splits(path='preprocessed_data/', train='trn.csv', validation='val.csv',\n",
        "                                           test='tst.csv', format='CSV', fields=fields, skip_header=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h9OU9HCNTaM"
      },
      "source": [
        "train_iter = BucketIterator(train, batch_size=8, sort_key=lambda x: len(x.text),\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
        "valid_iter = BucketIterator(valid, batch_size=8, sort_key=lambda x: len(x.text),\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
        "test_iter = Iterator(test, batch_size=8, device=device, train=False, shuffle=False, sort=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWKv873sNTaM"
      },
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, pred = self.encoder(text, labels=label)[:2]\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "        return loss, pred"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A2wt9fjNTaN"
      },
      "source": [
        "# Training Function\n",
        "\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          train_loader = train_iter,\n",
        "          valid_loader = valid_iter,\n",
        "          num_epochs = 10,):\n",
        "    \n",
        "    # initialize running values\n",
        "    running_loss = 0.0\n",
        "#     valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "#     train_loss_list = []\n",
        "#     valid_loss_list = []\n",
        "\n",
        "    total_acc = 0\n",
        "    # training loop\n",
        "    model.train()\n",
        "    total_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        acc = 0\n",
        "        seen = 0\n",
        "        for batch in train_loader:   \n",
        "            text = batch.text\n",
        "            labels = batch.label\n",
        "            labels = labels.to(device)\n",
        "            text = text.to(device)\n",
        "            # text = text.type(torch.LongTensor)\n",
        "            # labels = labels.type(torch.LongTensor)\n",
        "            output = model(text, labels)\n",
        "            loss, pred = output\n",
        "            acc += torch.eq(pred, labels).sum().item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            epoch_loss += loss.item()\n",
        "            global_step += 1\n",
        "            seen += 8\n",
        "        acc = acc/seen\n",
        "        print(acc)\n",
        "    torch.save(model.state_dict(), 'weights.pt')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l3RpG1SQNTaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8d7d9c-4f75-4c02-ce3f-2757afdd629b"
      },
      "source": [
        "model = BERT()\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model, optimizer=optimizer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9676126240773734\n",
            "0.9859697123950114\n",
            "0.9929689488419445\n",
            "0.9954823110206159\n",
            "0.9972321201323492\n",
            "0.9976457113769407\n",
            "0.9981547467548995\n",
            "0.9987592262662255\n",
            "0.9984410791550012\n",
            "0.9984728938661237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXiIRSebwAAC"
      },
      "source": [
        "# TODO ADD TIMER"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "effNdcaFwAkh"
      },
      "source": [
        "# TODO ADD PREDICT FUNCTION \n",
        "def predict(text, label, model):\n",
        "  text = tokenizer.encode(text)\n",
        "  text=torch.tensor(text)\n",
        "  text = text.unsqueeze(0)\n",
        "  label = torch.tensor(label)\n",
        "  label = label.unsqueeze(0)\n",
        "  text = text.to(device)\n",
        "  label = label.to(device)\n",
        "  model=model.to(device)\n",
        "  loss, pred = model(text, label)\n",
        "  return pred.item()\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ABaLaKtzM13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f91315-c6b5-47a4-f564-19451c0b5d5a"
      },
      "source": [
        "text = 'Leading Republican Corker says Trump immigration order poorly implemented'\n",
        "label = 1\n",
        "output = predict(text, label, model)\n",
        "print(output)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jVVpnVyRGQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}