{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T7Krt3hr1CT",
        "outputId": "73e3775e-e954-4ac9-dfee-7e331fa58793"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOtN73NQrMTK"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4vm0TFNrTS8",
        "outputId": "fbf08797-805d-40f8-aea4-503d64db8517"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "print(torch.randn(5))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jrPYw5frbN0"
      },
      "source": [
        "y_trn = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_trn_title_labels.pkl\", \"rb\"))\n",
        "y_val = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_val_title_labels.pkl\", \"rb\"))\n",
        "y_tst = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_tst_title_labels.pkl\", \"rb\"))"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5In0jsNrcwY"
      },
      "source": [
        "x_trn = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_trn_title.pkl\", \"rb\")).tolist()\n",
        "x_val = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_val_title.pkl\", \"rb\")).tolist()\n",
        "x_tst = pickle.load(open(\"./drive/MyDrive/elmo_embeddings/elmo_tst_title.pkl\", \"rb\")).tolist()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJpmKcowruMn"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "## Training set\n",
        "trn_dataset = []\n",
        "for i in range(len(x_trn)):\n",
        "    trn_dataset.append((torch.tensor(x_trn[i]), y_trn[i]))\n",
        "\n",
        "del x_trn\n",
        "del y_trn\n",
        "trn_dataloader = DataLoader(trn_dataset, batch_size)\n",
        "\n",
        "### Validation set\n",
        "val_dataset = []\n",
        "for i in range(len(x_val)):\n",
        "    val_dataset.append((torch.tensor(x_val[i]), y_val[i]))\n",
        "\n",
        "del x_val\n",
        "del y_val\n",
        "val_dataloader = DataLoader(val_dataset, batch_size)\n",
        "\n",
        "### Test set\n",
        "tst_dataset = []\n",
        "for i in range(len(x_tst)):\n",
        "    tst_dataset.append((torch.tensor(x_tst[i]), y_tst[i]))\n",
        "\n",
        "del x_tst\n",
        "del y_tst\n",
        "tst_dataloader = DataLoader(tst_dataset, batch_size)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_O22dDDsUIP",
        "outputId": "07f3ec0a-8678-4e5e-d86b-5ac0e26db96c"
      },
      "source": [
        "val_iter = iter(val_dataloader)\n",
        "\n",
        "i = next(val_iter)\n",
        "\n",
        "print(i[0].shape) # B x L x E \n",
        "print(i[1].shape)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 7, 1024])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpGYzLzZDuzu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ttEnkxWs1a_"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_size, output_size, num_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.embedding_dim = embedding_dim \n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size \n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size) # fully connected layer \n",
        "  def init_state(self, batch_size): # create dummy state for (h0, c0)\n",
        "    return (torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    hidden = self.init_state(batch_size)\n",
        "    output, hidden = self.lstm(x, hidden)\n",
        "    fc_output = self.fc(hidden)\n",
        "    print(fc_output.shape)\n",
        "    return fc_output"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDYbeOBwDdJD"
      },
      "source": [
        "def train(model, trn_dataloader, optimizer, criterion, device=torch.device('cpu')):\n",
        "    total_batch, correct_pred, total_sample = 0, 0, 0\n",
        "    model.train()\n",
        "\n",
        "    for batch, label in trn_dataloader:\n",
        "        total_batch += 1\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        h0, c0 = model.init_state(batch.shape[0])\n",
        "        h0 = h0.to(device)\n",
        "        c0 = c0.to(device)\n",
        "        output = model(batch, (h0, c0))\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        clip_grad_norm(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        trn_loss = loss.data.item()\n",
        "        pred_label = output.argmax(dim=1)\n",
        "        correct_pred += (pred_label == label).sum()\n",
        "        total_sample += label.size()[0]\n",
        "\n",
        "        if total_batch % 50 == 0:\n",
        "            print(f\"#{total_batch}: trn loss = {trn_loss:.4f} | trn acc = {(correct_pred/total_sample):.4f}\")\n",
        "        \n",
        "    return model\n",
        "\n",
        "def eval(model, dataloader, criterion, device=torch.device('cpu')):\n",
        "    total_loss, total_batch = 0, 0\n",
        "    correct_pred, total_sample = 0, 0\n",
        "    model.eval()\n",
        "\n",
        "    for batch, label in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(batch)\n",
        "\n",
        "        total_batch += 1\n",
        "        loss = criterion(output, label)\n",
        "        total_loss += loss.data.item()\n",
        "\n",
        "        pred_label = output.argmax(dim=1)\n",
        "        correct_pred += (pred_label == label).sum()\n",
        "        total_sample += label.size()[0]\n",
        "\n",
        "    avg_loss = total_loss / total_batch\n",
        "    acc = correct_pred.item() / total_sample\n",
        "\n",
        "    return avg_loss, acc"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "4xkh0F_OvYwX",
        "outputId": "57910531-93c8-4b5d-9fa8-b1be3d78b3c0"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = RNN(1024, 128, 2, 1).to(device)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for e in range(5):\n",
        "    print(f'Epoch {e}\\n') if e == 0 else print(f'\\nEpoch {e}\\n')\n",
        "    model = train(model, trn_dataloader, optimizer, criterion, device)\n",
        "    trn_loss, trn_acc = eval(model, trn_dataloader, criterion, device)\n",
        "    val_loss, val_acc = eval(model, val_dataloader, criterion, device)\n",
        "    print(f\"\\ntrn loss = {trn_loss} trn acc = {trn_acc} val loss = {val_loss} val acc = {val_acc}\")"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-4024d0d4cc64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {e}\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nEpoch {e}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrn_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-eaea07ef049c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trn_dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    }
  ]
}