{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4T7Krt3hr1CT",
    "outputId": "73e3775e-e954-4ac9-dfee-7e331fa58793"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qOtN73NQrMTK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4vm0TFNrTS8",
    "outputId": "fbf08797-805d-40f8-aea4-503d64db8517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519])\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(torch.randn(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2jrPYw5frbN0"
   },
   "outputs": [],
   "source": [
    "y_trn = pickle.load(open(\"../preprocessed_embeddings/elmo_trn_title_labels.pkl\", \"rb\"))\n",
    "y_val = pickle.load(open(\"../preprocessed_embeddings/elmo_val_title_labels.pkl\", \"rb\"))\n",
    "y_tst = pickle.load(open(\"../preprocessed_embeddings/elmo_tst_title_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d5In0jsNrcwY"
   },
   "outputs": [],
   "source": [
    "x_trn = pickle.load(open(\"../preprocessed_embeddings/elmo_trn_title.pkl\", \"rb\")).tolist()\n",
    "x_val = pickle.load(open(\"../preprocessed_embeddings/elmo_val_title.pkl\", \"rb\")).tolist()\n",
    "x_tst = pickle.load(open(\"../preprocessed_embeddings/elmo_tst_title.pkl\", \"rb\")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tJpmKcowruMn"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "## Training set\n",
    "trn_dataset = []\n",
    "for i in range(len(x_trn)):\n",
    "    trn_dataset.append((torch.tensor(x_trn[i]), y_trn[i]))\n",
    "\n",
    "del x_trn\n",
    "del y_trn\n",
    "trn_dataloader = DataLoader(trn_dataset, batch_size)\n",
    "\n",
    "### Validation set\n",
    "val_dataset = []\n",
    "for i in range(len(x_val)):\n",
    "    val_dataset.append((torch.tensor(x_val[i]), y_val[i]))\n",
    "\n",
    "del x_val\n",
    "del y_val\n",
    "val_dataloader = DataLoader(val_dataset, batch_size)\n",
    "\n",
    "### Test set\n",
    "tst_dataset = []\n",
    "for i in range(len(x_tst)):\n",
    "    tst_dataset.append((torch.tensor(x_tst[i]), y_tst[i]))\n",
    "\n",
    "del x_tst\n",
    "del y_tst\n",
    "tst_dataloader = DataLoader(tst_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6ttEnkxWs1a_"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self, embedding_dim, hidden_size, output_size, num_layers=1):\n",
    "    super(RNN, self).__init__()\n",
    "    self.embedding_dim = embedding_dim \n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size \n",
    "    self.num_layers = num_layers\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "    self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(self.hidden_size, self.output_size) # fully connected layer \n",
    "  def init_state(self, batch_size): # create dummy state for (h0, c0)\n",
    "    return (torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "  def forward(self, x):\n",
    "    batch_size = x.shape[0]\n",
    "    h0, c0 = self.init_state(batch_size)\n",
    "    h0 = h0.to(device)\n",
    "    c0 = c0.to(device)\n",
    "    output, hidden = self.lstm(x, (h0, c0))\n",
    "    fc_output = self.fc(output)\n",
    "    fc_output = torch.sum(fc_output, dim=1)\n",
    "#     print(fc_output.shape)\n",
    "    return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "LH7ZaESkLLdZ",
    "outputId": "01901451-6353-4829-9c4c-3fa807ce16c3"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm\n",
    "grad_clip = 1.0\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def batch_train(batch, labels, model, optimizer):\n",
    "    model.train()\n",
    "    texts = batch.to(device)\n",
    "    h0, c0 = model.init_state(batch_size=texts.shape[0])\n",
    "    h0 = h0.to(device)\n",
    "    c0 = c0.to(device)\n",
    "    \n",
    "    predictions = model(texts)\n",
    "    targets = labels.to(device)\n",
    "    cost_function = nn.CrossEntropyLoss()\n",
    "    h0 = h0.detach() \n",
    "    c0 = c0.detach()\n",
    "\n",
    "    # Cross Entropy Loss \n",
    "    loss = cost_function(predictions, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    clip_grad_norm(model.parameters(), grad_clip)\n",
    "    optimizer.step()\n",
    "    return model, loss.item()\n",
    "\n",
    "def eval(data_loader, model):\n",
    "    # set in the eval model, which will trun off the features only used for training, such as droput\n",
    "    model.eval()\n",
    "    # records\n",
    "    val_loss, val_batch = 0, 0 \n",
    "    correct_pred, total_sample = 0, 0\n",
    "    # iterate all the mini batches for evaluation\n",
    "    for batch, label in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        label = label.to(device)\n",
    "        # Forward: prediction\n",
    "        h0, c0 = model.init_state(batch_size=batch.shape[0])\n",
    "        h0 = h0.to(device)\n",
    "        c0 = c0.to(device)\n",
    "        predictions = model(batch)\n",
    "        \n",
    "        pred_label = predictions.argmax(dim=1)\n",
    "        correct_pred += (pred_label == label).sum().item()\n",
    "        total_sample += label.size()[0]\n",
    "        \n",
    "        cost_function = nn.CrossEntropyLoss()\n",
    "        h0 = h0.detach() \n",
    "        c0 = c0.detach()\n",
    "        loss = cost_function(predictions, label)\n",
    "\n",
    "        val_batch += 1\n",
    "        val_loss += loss.item()\n",
    "    return (val_loss/val_batch), (correct_pred/total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 50, Trn loss: 0.02708, Trn acc: 0.99593, Val loss: 0.02488, Val acc: 0.99469\n",
      "Epoch: 0, Batch: 100, Trn loss: 0.03575, Trn acc: 0.99535, Val loss: 0.04111, Val acc: 0.99074\n",
      "Epoch: 0, Batch: 150, Trn loss: 0.01222, Trn acc: 0.99781, Val loss: 0.01935, Val acc: 0.99480\n",
      "Epoch: 0, Batch: 200, Trn loss: 0.03533, Trn acc: 0.98841, Val loss: 0.07382, Val acc: 0.97154\n",
      "\n",
      "\n",
      "Epoch: 1, Batch: 50, Trn loss: 0.01130, Trn acc: 0.99726, Val loss: 0.01567, Val acc: 0.99593\n",
      "Epoch: 1, Batch: 100, Trn loss: 0.00572, Trn acc: 0.99832, Val loss: 0.01022, Val acc: 0.99684\n",
      "Epoch: 1, Batch: 150, Trn loss: 0.00390, Trn acc: 0.99884, Val loss: 0.01138, Val acc: 0.99639\n",
      "Epoch: 1, Batch: 200, Trn loss: 0.01513, Trn acc: 0.99377, Val loss: 0.04792, Val acc: 0.98035\n",
      "\n",
      "\n",
      "Epoch: 2, Batch: 50, Trn loss: 0.01205, Trn acc: 0.99758, Val loss: 0.02662, Val acc: 0.99503\n",
      "Epoch: 2, Batch: 100, Trn loss: 0.00731, Trn acc: 0.99852, Val loss: 0.01766, Val acc: 0.99639\n",
      "Epoch: 2, Batch: 150, Trn loss: 0.00431, Trn acc: 0.99903, Val loss: 0.01520, Val acc: 0.99559\n",
      "Epoch: 2, Batch: 200, Trn loss: 0.06591, Trn acc: 0.97912, Val loss: 0.15643, Val acc: 0.95888\n",
      "\n",
      "\n",
      "Epoch: 3, Batch: 50, Trn loss: 0.00482, Trn acc: 0.99874, Val loss: 0.01168, Val acc: 0.99582\n",
      "Epoch: 3, Batch: 100, Trn loss: 0.00978, Trn acc: 0.99781, Val loss: 0.02485, Val acc: 0.99458\n",
      "Epoch: 3, Batch: 150, Trn loss: 0.00188, Trn acc: 0.99932, Val loss: 0.01079, Val acc: 0.99672\n",
      "Epoch: 3, Batch: 200, Trn loss: 0.00453, Trn acc: 0.99813, Val loss: 0.01507, Val acc: 0.99514\n",
      "\n",
      "\n",
      "Epoch: 4, Batch: 50, Trn loss: 0.00310, Trn acc: 0.99919, Val loss: 0.01669, Val acc: 0.99684\n",
      "Epoch: 4, Batch: 100, Trn loss: 0.00427, Trn acc: 0.99897, Val loss: 0.02502, Val acc: 0.99559\n",
      "Epoch: 4, Batch: 150, Trn loss: 0.00284, Trn acc: 0.99890, Val loss: 0.01473, Val acc: 0.99605\n",
      "Epoch: 4, Batch: 200, Trn loss: 0.00332, Trn acc: 0.99881, Val loss: 0.01277, Val acc: 0.99559\n"
     ]
    }
   ],
   "source": [
    "model = RNN(embedding_dim=1024, hidden_size=128, output_size=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "epoch = 5\n",
    "total_batch = 0\n",
    "val_step = 50\n",
    "best_val_loss = 20\n",
    "for e in range(epoch):\n",
    "    if total_batch > 0:\n",
    "        print('\\n')\n",
    "        total_batch = 0\n",
    "    for batch, label in trn_dataloader:\n",
    "        total_batch += 1\n",
    "        # Update parameters with one batch\n",
    "        model, loss = batch_train(batch, label, model, optimizer)\n",
    "        # Compute validation loss after each val_step\n",
    "        if total_batch % val_step == 0:\n",
    "            val_loss, val_acc = eval(val_dataloader, model)\n",
    "            trn_loss, trn_acc = eval(trn_dataloader, model)\n",
    "              \n",
    "            print(f\"Epoch: {e}, Batch: {total_batch},\"\n",
    "                  f\" Trn loss: {trn_loss:.5f}, Trn acc: {trn_acc:.5f},\"\n",
    "                  f\" Val loss: {val_loss:.5f}, Val acc: {val_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}